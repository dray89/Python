{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "52930c23-70ee-4e15-b5e7-4c41fb59199d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark\n",
    "from operator import add\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark import SparkFiles\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import * \n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.ml.linalg import DenseVector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c06eab2-cabd-4a78-b099-cbc21539c769",
   "metadata": {},
   "source": [
    "#### Create a Dataframe\n",
    "Here I create a simple data frame for a demonstration on how to create dataframes in PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcabe388-023f-4b32-bf0c-1b6d9941955f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/Cellar/apache-spark/3.2.1/libexec/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/04/26 11:21:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+\n",
      "|language|users_count|\n",
      "+--------+-----------+\n",
      "|    Java|      20000|\n",
      "|  Python|     100000|\n",
      "|   Scala|       3000|\n",
      "+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Create SparkSession\n",
    "spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n",
    "# or an example: sc = SparkContext(\"local\", \"first app\")\n",
    "# Data\n",
    "data = [(\"Java\", \"20000\"), (\"Python\", \"100000\"), (\"Scala\", \"3000\")]\n",
    "\n",
    "# Columns\n",
    "columns = [\"language\",\"users_count\"]\n",
    "\n",
    "# Create DataFrame\n",
    "df = spark.createDataFrame(data).toDF(*columns)\n",
    "\n",
    "# Print DataFrame\n",
    "df.show()\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5915fb-c2f2-4104-b1d0-56e6ccfa6661",
   "metadata": {},
   "source": [
    "#### Parallelize\n",
    "The parallelize method allows Spark to distribute the data across multiple nodes, instead of depending on a single node to process the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f2c774e-716f-4d3e-8aeb-d97e079c1b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext(\"local\", \"first app\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c0d9a85-5528-477a-a4d6-131f79af63b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = sc.parallelize (\n",
    "   [\"scala\", \n",
    "   \"java\", \n",
    "   \"hadoop\", \n",
    "   \"spark\", \n",
    "   \"akka\",\n",
    "   \"spark vs hadoop\", \n",
    "   \"pyspark\",\n",
    "   \"pyspark and spark\"]\n",
    ")\n",
    "counts = words.count()\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49c1fc2a-7391-4b1f-b95b-c0d54def594e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scala',\n",
       " 'java',\n",
       " 'hadoop',\n",
       " 'spark',\n",
       " 'akka',\n",
       " 'spark vs hadoop',\n",
       " 'pyspark',\n",
       " 'pyspark and spark']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c96e4c43-3c89-4ebf-8271-6255b370b44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printWords(x):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d8bdbb3-30c2-4525-8b1b-5a6e80ace005",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "scala\n",
      "java\n",
      "hadoop\n",
      "spark\n",
      "akka\n",
      "spark vs hadoop\n",
      "pyspark\n",
      "pyspark and spark\n"
     ]
    }
   ],
   "source": [
    "fore = words.foreach(printWords) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c04f38e-d883-42a9-8c44-2437ef92a0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_filter = words.filter(lambda x: 'spark' in x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fcfbd45-5928-4741-a00a-92e66b03f450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[3] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "788d172c-12b3-4483-b057-251c71acf1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = words_filter.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0d5411d-0034-4c12-b2e9-d3b8038fbc1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['spark', 'spark vs hadoop', 'pyspark', 'pyspark and spark']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6578e124-f8bc-4ac2-988d-017fd4f4ed24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[4] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_map = words.map(lambda x: (x, 1))\n",
    "words_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28871666-e252-497e-850b-d1b7246662a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = words_map.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aee3bd9e-0fa9-45e0-9624-9d18abb451c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('scala', 1),\n",
       " ('java', 1),\n",
       " ('hadoop', 1),\n",
       " ('spark', 1),\n",
       " ('akka', 1),\n",
       " ('spark vs hadoop', 1),\n",
       " ('pyspark', 1),\n",
       " ('pyspark and spark', 1)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29500a87-7f2c-4df4-a5bf-6ce1aeae479b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParallelCollectionRDD[5] at readRDDFromFile at PythonRDD.scala:274"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nums = sc.parallelize([1, 2, 3, 4, 5])\n",
    "nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2bc2b4c-7bfb-400b-9745-1315541f2ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "adding = nums.reduce(add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab09ca85-fb45-49d5-9657-77269116422e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94626ec7-0a03-455b-881a-9dc29922fdb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "x = sc.parallelize([('spark', 1), ('hadoop', 4)])\n",
    "y = sc.parallelize([('spark', 2), ('hadoop', 5)])\n",
    "joined = x.join(y)\n",
    "final = joined.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d859c99-eda6-4860-a63b-aa49ca58e760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hadoop', (4, 5)), ('spark', (1, 2))]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9456cda4-6e32-410c-865e-d10e427091ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParallelCollectionRDD[0] at readRDDFromFile at PythonRDD.scala:274"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc343b02-8a90-4b16-92e4-a7ac18d1346c",
   "metadata": {},
   "outputs": [],
   "source": [
    "caching = words.persist().is_cached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c786c416-2ad5-4d2b-98fd-48729a805969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03eb883c-451d-4ccd-b20d-f2d3ff4e8898",
   "metadata": {},
   "source": [
    "## Broadcast variables are used to save the copy of data across all nodes. \n",
    "##### This variable is cached on all the machines and not sent on machines with tasks. \n",
    "##### The following code block has the details of a Broadcast class for PySpark.\n",
    "```\n",
    "class pyspark.Broadcast (\n",
    "   sc = None, \n",
    "   value = None, \n",
    "   pickle_registry = None, \n",
    "   path = None\n",
    ")\n",
    "```\n",
    "\n",
    "#####  A Broadcast variable has an attribute called value, which stores the data and is used to return a broadcasted value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e60bb856-eff5-4245-99b3-17570975efb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_new = sc.broadcast([\"scala\", \"java\", \"hadoop\", \"spark\", \"akka\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e2883de9-cf55-49c5-a9a8-9e240886a9f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scala', 'java', 'hadoop', 'spark', 'akka']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_new.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5bbc9f1d-982e-4a3a-a2c7-f9b1cb0cfe44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hadoop'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_new.value[2] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e7d1cb-ece5-46fb-b3c7-9dee311c57cf",
   "metadata": {},
   "source": [
    "The following example shows how to use an Accumulator variable. An Accumulator variable has an attribute called value that is similar to what a broadcast variable has. It stores the data and is used to return the accumulator's value, but usable only in a driver program.\n",
    "\n",
    "In this example, an accumulator variable is used by multiple workers and returns an accumulated value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1943d56d-a45e-4a49-a12c-d636d96e34b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accumulator<id=0, value=10>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num = sc.accumulator(10)\n",
    "num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cb363afb-23dd-4452-bac7-e4be025deb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    global num #need to specify num\n",
    "    num +=x \n",
    "rdd = sc.parallelize([20,30,40,50])\n",
    "rdd.foreach(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c06136b9-223b-4148-8bc9-2676c895edb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = num.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8a519788-8f8a-4de0-9b09-65d61fc35c73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46736ac-53b9-4161-8f84-ceb40c4a6f85",
   "metadata": {},
   "source": [
    "StorageLevel decides how RDD should be stored. In Apache Spark, StorageLevel decides whether RDD should be stored in the memory or should it be stored over the disk, or both. It also decides whether to serialize RDD and whether to replicate RDD partitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7bfe0b22-ca1c-427e-bd20-297d6ccf72e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disk Memory Serialized 2x Replicated\n"
     ]
    }
   ],
   "source": [
    "rdd1 = sc.parallelize([1,2])\n",
    "rdd1.persist( pyspark.StorageLevel.MEMORY_AND_DISK_2 )\n",
    "rdd1.getStorageLevel()\n",
    "print(rdd1.getStorageLevel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f367b987-c489-4609-b113-f28de9404710",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "45980b7a-6363-4603-b522-6df6c7326018",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4, 3]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc = SparkContext()\n",
    "nums = sc.parallelize([4,3,2,1])\n",
    "nums.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c18d812e-5624-49b2-be8c-8d1078df5c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 \n",
      "9 \n",
      "4 \n",
      "1 \n"
     ]
    }
   ],
   "source": [
    "squared = nums.map(lambda x: x*x).collect()\n",
    "for num in squared:\n",
    "    print('%i ' % (num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0ec6d426-8f55-4311-b157-a00ab7e92218",
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlContext = SQLContext(sc)\n",
    "lp = [('John',19),('Smith',29),('Adam',35),('Henry',50)]\n",
    "rdd = sc.parallelize(lp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c2474687-b273-49ee-ad1c-8fbe1b62581e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppl = rdd.map(lambda x: Row(name=x[0], age=int(x[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0878bfee-2f0b-4eb2-a8fa-bf3c55b6a9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sqlContext.createDataFrame(ppl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "633d7273-5a7f-4a33-87f5-3a70445b031a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+\n",
      "| name|age|\n",
      "+-----+---+\n",
      "| John| 19|\n",
      "|Smith| 29|\n",
      "| Adam| 35|\n",
      "|Henry| 50|\n",
      "+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dc3f008f-5131-4662-9240-a484624d2f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "29b8e740-5270-4012-b064-aad67ab81678",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/04/26 14:22:49 WARN SparkContext: The path https://raw.githubusercontent.com/guru99-edu/R-Programming/master/adult_data.csv has been added already. Overwriting of added paths is not supported in the current version.\n"
     ]
    }
   ],
   "source": [
    "url = \"https://raw.githubusercontent.com/guru99-edu/R-Programming/master/adult_data.csv\"\n",
    "sc.addFile(url)\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "b42b3808-9f01-4b56-8d1c-965087223e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = sqlContext.read.csv(SparkFiles.get(\"adult_data.csv\"), header=True, inferSchema= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "22c6301b-07ed-43ef-8336-1ad485dbbfb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- x: integer (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- workclass: string (nullable = true)\n",
      " |-- fnlwgt: integer (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- educational-num: integer (nullable = true)\n",
      " |-- marital-status: string (nullable = true)\n",
      " |-- occupation: string (nullable = true)\n",
      " |-- relationship: string (nullable = true)\n",
      " |-- race: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- capital-gain: integer (nullable = true)\n",
      " |-- capital-loss: integer (nullable = true)\n",
      " |-- hours-per-week: integer (nullable = true)\n",
      " |-- native-country: string (nullable = true)\n",
      " |-- income: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "295a7955-6583-478c-b238-4777acec3007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---------+------+------------+---------------+------------------+-----------------+------------+-----+------+------------+------------+--------------+--------------+------+\n",
      "|x  |age|workclass|fnlwgt|education   |educational-num|marital-status    |occupation       |relationship|race |gender|capital-gain|capital-loss|hours-per-week|native-country|income|\n",
      "+---+---+---------+------+------------+---------------+------------------+-----------------+------------+-----+------+------------+------------+--------------+--------------+------+\n",
      "|1  |25 |Private  |226802|11th        |7              |Never-married     |Machine-op-inspct|Own-child   |Black|Male  |0           |0           |40            |United-States |<=50K |\n",
      "|2  |38 |Private  |89814 |HS-grad     |9              |Married-civ-spouse|Farming-fishing  |Husband     |White|Male  |0           |0           |50            |United-States |<=50K |\n",
      "|3  |28 |Local-gov|336951|Assoc-acdm  |12             |Married-civ-spouse|Protective-serv  |Husband     |White|Male  |0           |0           |40            |United-States |>50K  |\n",
      "|4  |44 |Private  |160323|Some-college|10             |Married-civ-spouse|Machine-op-inspct|Husband     |Black|Male  |7688        |0           |40            |United-States |>50K  |\n",
      "|5  |18 |?        |103497|Some-college|10             |Never-married     |?                |Own-child   |White|Female|0           |0           |30            |United-States |<=50K |\n",
      "+---+---+---------+------+------------+---------------+------------------+-----------------+------------+-----+------+------------+------------+--------------+--------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7c7546cc-0836-4f3f-94af-300381780e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- x: string (nullable = true)\n",
      " |-- age: string (nullable = true)\n",
      " |-- workclass: string (nullable = true)\n",
      " |-- fnlwgt: string (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- educational-num: string (nullable = true)\n",
      " |-- marital-status: string (nullable = true)\n",
      " |-- occupation: string (nullable = true)\n",
      " |-- relationship: string (nullable = true)\n",
      " |-- race: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- capital-gain: string (nullable = true)\n",
      " |-- capital-loss: string (nullable = true)\n",
      " |-- hours-per-week: string (nullable = true)\n",
      " |-- native-country: string (nullable = true)\n",
      " |-- income: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_string = sqlContext.read.csv(SparkFiles.get(\"adult_data.csv\"), header=True, inferSchema= False)\n",
    "#example: all string - must convert\n",
    "df_string.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "47da528e-6a16-42a4-9602-6c3e499704b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convertColumn(df, names, newType):\n",
    "    for name in names:\n",
    "        df = df.withColumn(name, df[name].cast(newType))\n",
    "    return df\n",
    "CONTI_FEATURES  = ['age', 'fnlwgt','capital-gain', 'educational-num', 'capital-loss', 'hours-per-week']\n",
    "df_string = convertColumn(df_string, CONTI_FEATURES, FloatType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3a92cc7d-8e54-41ae-a759-d85e08e7f805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- x: string (nullable = true)\n",
      " |-- age: float (nullable = true)\n",
      " |-- workclass: string (nullable = true)\n",
      " |-- fnlwgt: float (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- educational-num: float (nullable = true)\n",
      " |-- marital-status: string (nullable = true)\n",
      " |-- occupation: string (nullable = true)\n",
      " |-- relationship: string (nullable = true)\n",
      " |-- race: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- capital-gain: float (nullable = true)\n",
      " |-- capital-loss: float (nullable = true)\n",
      " |-- hours-per-week: float (nullable = true)\n",
      " |-- native-country: string (nullable = true)\n",
      " |-- income: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_string.printSchema() # Now the number strings have been converted to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2af27686-881c-43d0-8cd0-f4852bd0102a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "|  x|age|\n",
      "+---+---+\n",
      "|  1| 25|\n",
      "|  2| 38|\n",
      "|  3| 28|\n",
      "|  4| 44|\n",
      "|  5| 18|\n",
      "|  6| 34|\n",
      "|  7| 29|\n",
      "|  8| 63|\n",
      "|  9| 24|\n",
      "| 10| 55|\n",
      "| 11| 65|\n",
      "| 12| 36|\n",
      "| 13| 26|\n",
      "| 14| 58|\n",
      "| 15| 48|\n",
      "| 16| 43|\n",
      "| 17| 20|\n",
      "| 18| 43|\n",
      "| 19| 37|\n",
      "| 20| 40|\n",
      "+---+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('x', 'age').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c82eadcc-7a55-4e2c-bfa4-b0d5f6539005",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:=============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|   education|count|\n",
      "+------------+-----+\n",
      "|   Preschool|   83|\n",
      "|     1st-4th|  247|\n",
      "|     5th-6th|  509|\n",
      "|   Doctorate|  594|\n",
      "|        12th|  657|\n",
      "|         9th|  756|\n",
      "| Prof-school|  834|\n",
      "|     7th-8th|  955|\n",
      "|        10th| 1389|\n",
      "|  Assoc-acdm| 1601|\n",
      "|        11th| 1812|\n",
      "|   Assoc-voc| 2061|\n",
      "|     Masters| 2657|\n",
      "|   Bachelors| 8025|\n",
      "|Some-college|10878|\n",
      "|     HS-grad|15784|\n",
      "+------------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#number of observations in each education group sorted by the count in ascending order\n",
    "df.groupby('education').count().sort('count', ascending=True).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fcd5a785-dbbb-4da7-a1a7-3bd7441f9d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 20:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+-----------+------------------+------------+------------------+--------------+----------------+------------+------------------+------+------------------+-----------------+------------------+--------------+------+\n",
      "|summary|                 x|               age|  workclass|            fnlwgt|   education|   educational-num|marital-status|      occupation|relationship|              race|gender|      capital-gain|     capital-loss|    hours-per-week|native-country|income|\n",
      "+-------+------------------+------------------+-----------+------------------+------------+------------------+--------------+----------------+------------+------------------+------+------------------+-----------------+------------------+--------------+------+\n",
      "|  count|             48842|             48842|      48842|             48842|       48842|             48842|         48842|           48842|       48842|             48842| 48842|             48842|            48842|             48842|         48842| 48842|\n",
      "|   mean|           24421.5| 38.64358543876172|       null|189664.13459727284|        null|10.078088530363212|          null|            null|        null|              null|  null|1079.0676262233324|87.50231358257237|40.422382375824085|          null|  null|\n",
      "| stddev|14099.615260708357|13.710509934443525|       null|105604.02542315757|        null| 2.570972755592259|          null|            null|        null|              null|  null| 7452.019057655418| 403.004552124359|12.391444024252312|          null|  null|\n",
      "|    min|                 1|                17|          ?|            100009|        10th|                 1|      Divorced|               ?|     Husband|Amer-Indian-Eskimo|Female|                 0|                0|                 1|             ?| <=50K|\n",
      "|    max|              9999|                90|Without-pay|             99987|Some-college|                 9|       Widowed|Transport-moving|        Wife|             White|  Male|             99999|              974|                99|    Yugoslavia|  >50K|\n",
      "+-------+------------------+------------------+-----------+------------------+------------+------------------+--------------+----------------+------------+------------------+------+------------------+-----------------+------------------+--------------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "026b6a7c-dca2-4039-a79c-145158bc1102",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 21:=============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|      capital-gain|\n",
      "+-------+------------------+\n",
      "|  count|             48842|\n",
      "|   mean|1079.0676262233324|\n",
      "| stddev| 7452.019057655418|\n",
      "|    min|                 0|\n",
      "|    max|             99999|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.describe('capital-gain').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5d7d7a-acf6-4b6e-9709-9bafa7366235",
   "metadata": {},
   "source": [
    "#### Crosstab computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "828d7535-7a83-4c52-8019-5fb3349d687a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---+-----------+---------+------------+-------+------------+----------------+---------+-----------+\n",
      "|age_workclass|  ?|Federal-gov|Local-gov|Never-worked|Private|Self-emp-inc|Self-emp-not-inc|State-gov|Without-pay|\n",
      "+-------------+---+-----------+---------+------------+-------+------------+----------------+---------+-----------+\n",
      "|           17| 97|          2|       21|           2|    454|           8|               9|        2|          0|\n",
      "|           18|154|          5|       15|           4|    638|          12|              20|       14|          0|\n",
      "|           19|183|          6|       18|           0|    784|           6|              24|       29|          3|\n",
      "|           20|184|         13|       20|           2|    834|          11|              16|       33|          0|\n",
      "|           21|147|          4|       22|           0|    859|           4|              15|       44|          1|\n",
      "|           22|128|         16|       34|           0|    924|           9|              19|       47|          1|\n",
      "|           23| 76|         20|       52|           1|   1098|           9|              24|       49|          0|\n",
      "|           24| 56|         21|       56|           0|    986|          10|              35|       42|          0|\n",
      "|           25| 46|         14|       64|           0|    980|          15|              36|       40|          0|\n",
      "|           26| 38|         23|       61|           0|    922|          16|              46|       47|          0|\n",
      "|           27| 51|         25|       72|           0|    964|          16|              58|       45|          1|\n",
      "|           28| 55|         23|       74|           0|    990|          21|              72|       45|          0|\n",
      "|           29| 48|         34|       71|           0|    942|          18|              66|       43|          1|\n",
      "|           30| 36|         27|       83|           1|    984|          26|              72|       49|          0|\n",
      "|           31| 25|         34|       83|           0|   1023|          28|              79|       53|          0|\n",
      "|           32| 35|         30|       69|           0|    940|          34|              91|       54|          0|\n",
      "|           33| 36|         35|       85|           0|    992|          28|             105|       54|          0|\n",
      "|           34| 36|         29|       90|           0|    947|          40|             102|       59|          0|\n",
      "|           35| 43|         36|       66|           0|    995|          37|             112|       48|          0|\n",
      "|           36| 36|         34|       90|           0|    989|          36|             108|       55|          0|\n",
      "+-------------+---+-----------+---------+------------+-------+------------+----------------+---------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.crosstab('age', 'workclass').sort('age_workclass').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55a2a4e-67e1-4e8d-989e-fb80ddb42617",
   "metadata": {},
   "source": [
    "#### More filtering and GroupBy Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "cfb1e907-943d-40b3-9831-14f6158914e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20211"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(df.age>40).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2c78a65c-fe37-47b0-aead-0b2c33018c84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28631"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(df.age<=40).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "489e8a4d-eac6-4d91-9b4b-7c963c7a6c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "|age|count|\n",
      "+---+-----+\n",
      "| 36| 1348|\n",
      "| 35| 1337|\n",
      "| 33| 1335|\n",
      "| 23| 1329|\n",
      "| 31| 1325|\n",
      "| 34| 1303|\n",
      "| 28| 1280|\n",
      "| 37| 1280|\n",
      "| 30| 1278|\n",
      "| 38| 1264|\n",
      "| 32| 1253|\n",
      "| 41| 1235|\n",
      "| 27| 1232|\n",
      "| 29| 1223|\n",
      "| 24| 1206|\n",
      "| 39| 1206|\n",
      "| 25| 1195|\n",
      "| 40| 1187|\n",
      "| 22| 1178|\n",
      "| 42| 1165|\n",
      "+---+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupby('age').count().sort('count', ascending=False).show() #only shows top 20 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d2907794-bf65-434d-93b8-15abb4fa15bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 50:=============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|      marital-status| avg(capital-gain)|\n",
      "+--------------------+------------------+\n",
      "|           Separated| 581.8424836601307|\n",
      "|       Never-married|  384.382639449029|\n",
      "|Married-spouse-ab...| 629.0047770700637|\n",
      "|            Divorced| 793.6755615860094|\n",
      "|             Widowed| 603.6442687747035|\n",
      "|   Married-AF-spouse|2971.6216216216217|\n",
      "|  Married-civ-spouse|1739.7006121810625|\n",
      "+--------------------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.groupby('marital-status').agg({'capital-gain': 'mean'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "530f4224-ed74-488d-b5a4-df412525f9ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|POWER(age, 2)|\n",
      "+-------------+\n",
      "|        625.0|\n",
      "|       1444.0|\n",
      "|        784.0|\n",
      "|       1936.0|\n",
      "|        324.0|\n",
      "|       1156.0|\n",
      "|        841.0|\n",
      "|       3969.0|\n",
      "|        576.0|\n",
      "|       3025.0|\n",
      "|       4225.0|\n",
      "|       1296.0|\n",
      "|        676.0|\n",
      "|       3364.0|\n",
      "|       2304.0|\n",
      "|       1849.0|\n",
      "|        400.0|\n",
      "|       1849.0|\n",
      "|       1369.0|\n",
      "|       1600.0|\n",
      "+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "age_square = df.select(col('age')**2)\n",
    "age_square.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a308823d-cab0-415c-8569-2bd835d485a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('age-square', col('age')**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5f4daf0a-5e39-4943-8745-3ba3a3a0af4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- x: string (nullable = true)\n",
      " |-- age: string (nullable = true)\n",
      " |-- workclass: string (nullable = true)\n",
      " |-- fnlwgt: string (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- educational-num: string (nullable = true)\n",
      " |-- marital-status: string (nullable = true)\n",
      " |-- occupation: string (nullable = true)\n",
      " |-- relationship: string (nullable = true)\n",
      " |-- race: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- capital-gain: string (nullable = true)\n",
      " |-- capital-loss: string (nullable = true)\n",
      " |-- hours-per-week: string (nullable = true)\n",
      " |-- native-country: string (nullable = true)\n",
      " |-- income: string (nullable = true)\n",
      " |-- age-square: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema() #age-square is now at the end of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "2e775d32-cd55-4123-b321-83348b838906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(x='1', age='25', workclass='Private', fnlwgt='226802', education='11th', educational-num='7', marital-status='Never-married', occupation='Machine-op-inspct', relationship='Own-child', race='Black', gender='Male', capital-gain='0', capital-loss='0', hours-per-week='40', native-country='United-States', income='<=50K', age-square=625.0)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61a22fe-3b0b-402f-8de0-e847d1352a8b",
   "metadata": {},
   "source": [
    "#### Build data processing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "6c4d71af-a3b6-4bd4-a13f-8d4357ef9612",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---------+------+---------+---------------+------------------+-----------------+------------+-----+------+------------+------------+--------------+--------------+------+----------+-----------------+-------------+\n",
      "|  x|age|workclass|fnlwgt|education|educational-num|    marital-status|       occupation|relationship| race|gender|capital-gain|capital-loss|hours-per-week|native-country|income|age-square|workclass_encoded|workclass_vec|\n",
      "+---+---+---------+------+---------+---------------+------------------+-----------------+------------+-----+------+------------+------------+--------------+--------------+------+----------+-----------------+-------------+\n",
      "|  1| 25|  Private|226802|     11th|              7|     Never-married|Machine-op-inspct|   Own-child|Black|  Male|           0|           0|            40| United-States| <=50K|     625.0|              0.0|(9,[0],[1.0])|\n",
      "|  2| 38|  Private| 89814|  HS-grad|              9|Married-civ-spouse|  Farming-fishing|     Husband|White|  Male|           0|           0|            50| United-States| <=50K|    1444.0|              0.0|(9,[0],[1.0])|\n",
      "+---+---+---------+------+---------+---------------+------------------+-----------------+------------+-----+------+------------+------------+--------------+--------------+------+----------+-----------------+-------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "indexer = StringIndexer(inputCol='workclass', outputCol='workclass_encoded')\n",
    "model = indexer.fit(df)\n",
    "indexed = model.transform(df)\n",
    "\n",
    "encoder = OneHotEncoder(dropLast=False, inputCol=\"workclass_encoded\", outputCol='workclass_vec')\n",
    "ohe = encoder.fit(indexed)\n",
    "encoded = ohe.transform(indexed)\n",
    "encoded.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c139ff97-e72a-402a-a1fb-2aa024a14f34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StringIndexer_bbcbaf9fe1e8,\n",
       " OneHotEncoder_f98fee62dfeb,\n",
       " StringIndexer_f157372b71fa,\n",
       " OneHotEncoder_9fedb6cd0798,\n",
       " StringIndexer_0f1d2d5a480e,\n",
       " OneHotEncoder_040a5d70f973,\n",
       " StringIndexer_ec76f2936067,\n",
       " OneHotEncoder_fbccd51a378f,\n",
       " StringIndexer_dea1f7df56d4,\n",
       " OneHotEncoder_880ab465f68d,\n",
       " StringIndexer_f0538640e59c,\n",
       " OneHotEncoder_bcea3f54ed37,\n",
       " StringIndexer_5c488a23f81d,\n",
       " OneHotEncoder_d0be1d80efb2,\n",
       " StringIndexer_cbe062c13dbf,\n",
       " OneHotEncoder_63fdd55aa9fe]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CATE_FEATURES = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'gender', 'native-country']\n",
    "stages = []\n",
    "for categoricalCol in CATE_FEATURES:\n",
    "    stringIndexer = StringIndexer(inputCol=categoricalCol, outputCol=categoricalCol + 'Index')\n",
    "    encoder = OneHotEncoder(inputCols = [stringIndexer.getOutputCol()], outputCols=[categoricalCol + 'classVec'])\n",
    "    stages += [stringIndexer, encoder]\n",
    "stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "202a8c7a-1721-4684-86f3-34645b5b437c",
   "metadata": {},
   "outputs": [],
   "source": [
    "assemblerInputs = [c + 'classVec' for c in CATE_FEATURES] + CONTI_FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "971a668b-b280-4961-989b-2861897f6ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=assemblerInputs, outputCol='features')\n",
    "stages += [assembler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "2812910d-381e-4bae-b4cb-b8874b1219d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- x: integer (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- workclass: string (nullable = true)\n",
      " |-- fnlwgt: integer (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- educational-num: integer (nullable = true)\n",
      " |-- marital-status: string (nullable = true)\n",
      " |-- occupation: string (nullable = true)\n",
      " |-- relationship: string (nullable = true)\n",
      " |-- race: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- capital-gain: integer (nullable = true)\n",
      " |-- capital-loss: integer (nullable = true)\n",
      " |-- hours-per-week: integer (nullable = true)\n",
      " |-- native-country: string (nullable = true)\n",
      " |-- income: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "19affb9b-ec2f-4fde-9ac1-a9b51a3f89dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=stages)\n",
    "pipelineModel = pipeline.fit(df)\n",
    "model = pipelineModel.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "3888decf-4e35-422d-aebf-0315f137e606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(x=1, age=25, workclass='Private', fnlwgt=226802, education='11th', educational-num=7, marital-status='Never-married', occupation='Machine-op-inspct', relationship='Own-child', race='Black', gender='Male', capital-gain=0, capital-loss=0, hours-per-week=40, native-country='United-States', income='<=50K', workclassIndex=0.0, workclassclassVec=SparseVector(8, {0: 1.0}), educationIndex=5.0, educationclassVec=SparseVector(15, {5: 1.0}), marital-statusIndex=1.0, marital-statusclassVec=SparseVector(6, {1: 1.0}), occupationIndex=6.0, occupationclassVec=SparseVector(14, {6: 1.0}), relationshipIndex=2.0, relationshipclassVec=SparseVector(5, {2: 1.0}), raceIndex=1.0, raceclassVec=SparseVector(4, {1: 1.0}), genderIndex=0.0, genderclassVec=SparseVector(1, {0: 1.0}), native-countryIndex=0.0, native-countryclassVec=SparseVector(41, {0: 1.0}), features=SparseVector(100, {0: 1.0, 13: 1.0, 24: 1.0, 35: 1.0, 45: 1.0, 49: 1.0, 52: 1.0, 53: 1.0, 94: 25.0, 95: 226802.0, 97: 7.0, 99: 40.0}))]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "5b37222c-1d82-44bc-8316-7f082bb8f74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = model.rdd.map(lambda x: (x['newlabel'], DenseVector(x['features'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "51c2d447-fda5-434a-a443-3c2656070fc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[392] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba758eb-b9a6-4cfc-9ece-5f977cfddb33",
   "metadata": {},
   "source": [
    "#### User defined functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "73174b33-c418-4568-9d4a-011f5abe0fac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.cube(s)>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cube(s):  \n",
    "    return s*s*s  \n",
    "spark.udf.register(\"cubewithPython\", cube)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40a83d0-7f40-4d0d-a4e8-945ff0ebcad8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
